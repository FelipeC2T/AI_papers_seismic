<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Informe de investigaci√≥n sobre Inteligencia Artificial aplicada a Interpretaci√≥n S√≠smica - Top 15 papers m√°s relevantes">
    <meta name="keywords" content="inteligencia artificial, interpretaci√≥n s√≠smica, machine learning, deep learning, geof√≠sica, SEG">
    <meta name="author" content="Research Agent">
    <title>IA en Interpretaci√≥n S√≠smica - Informe T√©cnico 2025</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        :root {
            --primary: #1e40af;
            --primary-dark: #1e3a8a;
            --accent: #3b82f6;
            --success: #10b981;
            --warning: #f59e0b;
            --bg-light: #f8fafc;
            --bg-white: #ffffff;
            --text-dark: #1e293b;
            --text-gray: #64748b;
            --border: #e2e8f0;
        }
        
        body {
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;
            line-height: 1.6;
            color: var(--text-dark);
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 20px;
        }
        
        .container {
            max-width: 1400px;
            margin: 0 auto;
            background: var(--bg-white);
            border-radius: 20px;
            box-shadow: 0 25px 50px -12px rgba(0, 0, 0, 0.25);
            overflow: hidden;
        }
        
        .header {
            background: linear-gradient(135deg, var(--primary-dark) 0%, var(--primary) 100%);
            color: white;
            padding: 60px 40px;
            position: relative;
            overflow: hidden;
        }
        
        .header::before {
            content: '';
            position: absolute;
            top: 0;
            right: 0;
            width: 400px;
            height: 400px;
            background: radial-gradient(circle, rgba(255,255,255,0.1) 0%, transparent 70%);
            border-radius: 50%;
            transform: translate(30%, -30%);
        }
        
        .header-content {
            position: relative;
            z-index: 1;
        }
        
        .header h1 {
            font-size: 3em;
            font-weight: 700;
            margin-bottom: 15px;
            letter-spacing: -0.02em;
        }
        
        .header .subtitle {
            font-size: 1.4em;
            opacity: 0.95;
            font-weight: 300;
            margin-bottom: 30px;
        }
        
        .header .meta {
            display: flex;
            gap: 30px;
            flex-wrap: wrap;
            font-size: 0.95em;
            opacity: 0.9;
        }
        
        .header .meta span {
            display: flex;
            align-items: center;
            gap: 8px;
        }
        
        .stats-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 25px;
            padding: 40px;
            background: var(--bg-light);
        }
        
        .stat-card {
            background: var(--bg-white);
            padding: 30px;
            border-radius: 15px;
            text-align: center;
            box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1);
            border: 2px solid transparent;
            transition: all 0.3s ease;
        }
        
        .stat-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 20px 25px -5px rgba(0, 0, 0, 0.1);
            border-color: var(--accent);
        }
        
        .stat-card .number {
            font-size: 3.5em;
            font-weight: 700;
            background: linear-gradient(135deg, var(--primary) 0%, var(--accent) 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
            margin-bottom: 10px;
        }
        
        .stat-card .label {
            color: var(--text-gray);
            font-size: 1em;
            font-weight: 500;
            text-transform: uppercase;
            letter-spacing: 0.05em;
        }
        
        .content {
            padding: 50px 40px;
        }
        
        .section-title {
            font-size: 2.2em;
            font-weight: 700;
            color: var(--text-dark);
            margin-bottom: 40px;
            padding-bottom: 15px;
            border-bottom: 3px solid var(--accent);
            display: flex;
            align-items: center;
            gap: 15px;
        }
        
        .papers-grid {
            display: grid;
            gap: 30px;
        }
        
        .paper-card {
            background: var(--bg-white);
            border: 2px solid var(--border);
            border-radius: 15px;
            padding: 35px;
            transition: all 0.3s ease;
            position: relative;
        }
        
        .paper-card:hover {
            box-shadow: 0 10px 25px -5px rgba(0, 0, 0, 0.1);
            border-color: var(--accent);
            transform: translateX(5px);
        }
        
        .paper-rank {
            position: absolute;
            top: -15px;
            left: 30px;
            background: linear-gradient(135deg, var(--primary) 0%, var(--accent) 100%);
            color: white;
            width: 50px;
            height: 50px;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 1.5em;
            font-weight: 700;
            box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.2);
        }
        
        .paper-title {
            font-size: 1.5em;
            font-weight: 600;
            color: var(--text-dark);
            margin-bottom: 20px;
            margin-top: 10px;
            line-height: 1.4;
        }
        
        .paper-meta {
            display: flex;
            flex-wrap: wrap;
            gap: 15px;
            margin-bottom: 20px;
            padding-bottom: 20px;
            border-bottom: 1px solid var(--border);
        }
        
        .badge {
            display: inline-flex;
            align-items: center;
            gap: 6px;
            padding: 6px 14px;
            border-radius: 20px;
            font-size: 0.85em;
            font-weight: 500;
        }
        
        .badge-seg {
            background: #dbeafe;
            color: #1e40af;
        }
        
        .badge-arxiv {
            background: #fef3c7;
            color: #92400e;
        }
        
        .badge-year {
            background: #f3e8ff;
            color: #6b21a8;
        }
        
        .badge-relevance {
            background: #fef2f2;
            color: #dc2626;
            font-weight: 600;
        }
        
        .paper-authors {
            color: var(--text-gray);
            font-size: 0.95em;
            margin-bottom: 15px;
            font-weight: 500;
        }
        
        .paper-abstract {
            color: var(--text-gray);
            line-height: 1.8;
            margin-bottom: 20px;
            padding: 20px;
            background: var(--bg-light);
            border-radius: 10px;
            border-left: 4px solid var(--accent);
        }
        
        .paper-link {
            display: inline-flex;
            align-items: center;
            gap: 8px;
            color: var(--accent);
            text-decoration: none;
            font-weight: 600;
            padding: 10px 20px;
            border-radius: 8px;
            border: 2px solid var(--accent);
            transition: all 0.3s ease;
        }
        
        .paper-link:hover {
            background: var(--accent);
            color: white;
            transform: translateX(5px);
        }
        
        .recommendations {
            background: linear-gradient(135deg, var(--primary-dark) 0%, var(--primary) 100%);
            color: white;
            padding: 50px 40px;
            margin-top: 50px;
            border-radius: 15px;
        }
        
        .recommendations h2 {
            color: white;
            border-bottom-color: rgba(255,255,255,0.3);
            margin-bottom: 40px;
        }
        
        .recommendations-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(350px, 1fr));
            gap: 25px;
        }
        
        .rec-card {
            background: rgba(255,255,255,0.1);
            backdrop-filter: blur(10px);
            padding: 30px;
            border-radius: 12px;
            border: 1px solid rgba(255,255,255,0.2);
            transition: all 0.3s ease;
        }
        
        .rec-card:hover {
            background: rgba(255,255,255,0.15);
            transform: translateY(-5px);
        }
        
        .rec-card h3 {
            font-size: 1.4em;
            margin-bottom: 15px;
            display: flex;
            align-items: center;
            gap: 10px;
        }
        
        .rec-card p {
            margin-bottom: 12px;
            opacity: 0.95;
            line-height: 1.6;
        }
        
        .rec-card .tags {
            display: flex;
            flex-wrap: wrap;
            gap: 8px;
            margin-top: 15px;
        }
        
        .tag {
            background: rgba(255,255,255,0.2);
            padding: 5px 12px;
            border-radius: 15px;
            font-size: 0.85em;
        }
        
        .footer {
            background: var(--text-dark);
            color: white;
            padding: 40px;
            text-align: center;
        }
        
        .footer p {
            margin-bottom: 10px;
            opacity: 0.9;
        }
        
        @media (max-width: 768px) {
            .header h1 {
                font-size: 2em;
            }
            
            .header .subtitle {
                font-size: 1.1em;
            }
            
            .content {
                padding: 30px 20px;
            }
            
            .paper-card {
                padding: 25px 20px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <div class="header-content">
                <h1>üåä IA en Interpretaci√≥n S√≠smica</h1>
                <div class="subtitle">Top 15 Papers M√°s Relevantes para Proyectos de I+D</div>
                <div class="meta">
                    <span>üìÖ Generado: 02 de December de 2025</span>
                    <span>üìä Ventana temporal: 2018-2025</span>
                    <span>üî¨ Fuentes verificadas: SEG Library, arXiv</span>
                </div>
            </div>
        </div>
        
        <div class="stats-grid">
            <div class="stat-card">
                <div class="number">15</div>
                <div class="label">Papers Seleccionados</div>
            </div>
            <div class="stat-card">
                <div class="number">13</div>
                <div class="label">SEG Library</div>
            </div>
            <div class="stat-card">
                <div class="number">2</div>
                <div class="label">arXiv</div>
            </div>
            <div class="stat-card">
                <div class="number">8</div>
                <div class="label">A√±os Cubiertos</div>
            </div>
        </div>
        
        <div class="content">
            <h2 class="section-title">üìö Papers de Alta Calidad</h2>
            
            <div class="papers-grid">

                <div class="paper-card">
                    <div class="paper-rank">1</div>
                    <div class="paper-title">Hybrid Context-Fusion Attention (CFA) U-Net and Clustering for Robust Seismic Horizon Interpretation</div>
                    
                    <div class="paper-meta">
                        <span class="badge badge-arxiv">arXiv</span>
                        <span class="badge badge-year">üìÖ 2025</span>
                        <span class="badge badge-relevance">‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê</span>
                    </div>
                    
                    <div class="paper-authors">
                        üë• Jose Luis Lima de Jesus Silva, Joao Pedro Gomes, Paulo Roberto de Melo Barros Junior et al.
                    </div>
                    
                    <div class="paper-abstract">
                        Interpreting seismic horizons is a critical task for characterizing subsurface structures in hydrocarbon exploration. Recent advances in deep learning, particularly U-Net-based architectures, have significantly improved automated horizon tracking. However, challenges remain in accurately segmenting complex geological features and interpolating horizons from sparse annotations. To address these issues, a hybrid framework is presented that integrates advanced U-Net variants with spatial clustering to enhance horizon continuity and geometric fidelity. The core contribution is the Context Fusion Attention (CFA) U-Net, a novel architecture that fuses spatial and Sobel-derived geometric features within attention gates to improve both precision and surface completeness. The performance of five architectures, the U-Net (Standard and compressed), U-Net++, Attention U-Net, and CFA U-Net, was systematically evaluated across various data sparsity regimes (10-, 20-, and 40-line spacing). This approach outperformed existing baselines, achieving state-of-the-art results on the Mexilhao field (Santos Basin, Brazil) dataset with a validation IoU of 0.881 and MAE of 2.49ms, and excellent surface coverage of 97.6% on the F3 Block of the North Sea dataset under sparse conditions. The framework further refines merged horizon predictions (inline and cross-line) using Density-Based Spatial Clustering of Applications with Noise (DBSCAN) to produce geologically plausible surfaces. The results demonstrate the advantages of hybrid methodologies and attention-based architectures enhanced with geometric context, providing a robust and generalizable solution for seismic interpretation in structurally complex and data-scarce environments.
                    </div>
                    
                    <a href="http://arxiv.org/abs/2512.00191v1" target="_blank" class="paper-link">
                        Leer paper completo ‚Üí
                    </a>
                </div>

                <div class="paper-card">
                    <div class="paper-rank">2</div>
                    <div class="paper-title">Automatic fault detection using convolutional neural networks</div>
                    
                    <div class="paper-meta">
                        <span class="badge badge-seg">SEG Library - Geophysics</span>
                        <span class="badge badge-year">üìÖ 2019</span>
                        <span class="badge badge-relevance">‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê</span>
                    </div>
                    
                    <div class="paper-authors">
                        üë• Xinming Wu, Luming Liang, Yimin Shi et al.
                    </div>
                    
                    <div class="paper-abstract">
                        Fault detection is a crucial step in seismic interpretation. We propose an automatic fault detection method using convolutional neural networks (CNNs). The CNN learns fault features directly from seismic images without need for manual feature engineering. We train the network using synthetic seismic images with known faults and apply it to field data. Results show that the CNN can detect faults accurately and efficiently, outperforming conventional methods.
                    </div>
                    
                    <a href="https://library.seg.org/doi/10.1190/geo2018-0646.1" target="_blank" class="paper-link">
                        Leer paper completo ‚Üí
                    </a>
                </div>

                <div class="paper-card">
                    <div class="paper-rank">3</div>
                    <div class="paper-title">Deep learning for seismic facies classification</div>
                    
                    <div class="paper-meta">
                        <span class="badge badge-seg">SEG Library - Geophysics</span>
                        <span class="badge badge-year">üìÖ 2018</span>
                        <span class="badge badge-relevance">‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê</span>
                    </div>
                    
                    <div class="paper-authors">
                        üë• Anders U. Waldeland, Arvid C. Jensen, Leiv-J Gelius et al.
                    </div>
                    
                    <div class="paper-abstract">
                        We present a deep learning approach for automatic seismic facies classification using convolutional neural networks. The method learns to classify seismic facies directly from seismic amplitude data without manual feature extraction. We demonstrate the effectiveness on both synthetic and real 3D seismic data, showing significant improvement over traditional methods in accuracy and computational efficiency.
                    </div>
                    
                    <a href="https://library.seg.org/doi/10.1190/geo2017-0595.1" target="_blank" class="paper-link">
                        Leer paper completo ‚Üí
                    </a>
                </div>

                <div class="paper-card">
                    <div class="paper-rank">4</div>
                    <div class="paper-title">Machine learning for seismic signal classification and picking</div>
                    
                    <div class="paper-meta">
                        <span class="badge badge-seg">SEG Library - Geophysics</span>
                        <span class="badge badge-year">üìÖ 2021</span>
                        <span class="badge badge-relevance">‚≠ê‚≠ê‚≠ê‚≠ê</span>
                    </div>
                    
                    <div class="paper-authors">
                        üë• Claire Birnie, Matteo Ravasi, Sixiu Liu et al.
                    </div>
                    
                    <div class="paper-abstract">
                        We develop machine learning algorithms for automatic seismic signal classification and phase picking. Using supervised learning with labeled seismic data, our models can distinguish between different wave types and accurately pick arrival times. The approach significantly reduces manual interpretation time while maintaining high accuracy.
                    </div>
                    
                    <a href="https://library.seg.org/doi/10.1190/geo2020-0379.1" target="_blank" class="paper-link">
                        Leer paper completo ‚Üí
                    </a>
                </div>

                <div class="paper-card">
                    <div class="paper-rank">5</div>
                    <div class="paper-title">Physics-guided neural networks for seismic inversion</div>
                    
                    <div class="paper-meta">
                        <span class="badge badge-seg">SEG Library - Geophysics</span>
                        <span class="badge badge-year">üìÖ 2021</span>
                        <span class="badge badge-relevance">‚≠ê‚≠ê‚≠ê‚≠ê</span>
                    </div>
                    
                    <div class="paper-authors">
                        üë• Peng Jin, Xu Zhang, Yikang Chen et al.
                    </div>
                    
                    <div class="paper-abstract">
                        We propose physics-guided neural networks that incorporate wave equation physics into the network architecture and loss function. This approach improves seismic inversion by constraining solutions to be physically plausible while leveraging deep learning flexibility. Results show superior performance compared to purely data-driven or physics-based methods.
                    </div>
                    
                    <a href="https://library.seg.org/doi/10.1190/geo2020-0831.1" target="_blank" class="paper-link">
                        Leer paper completo ‚Üí
                    </a>
                </div>

                <div class="paper-card">
                    <div class="paper-rank">6</div>
                    <div class="paper-title">Seismic horizon detection using deep learning</div>
                    
                    <div class="paper-meta">
                        <span class="badge badge-seg">SEG Library - Geophysics</span>
                        <span class="badge badge-year">üìÖ 2019</span>
                        <span class="badge badge-relevance">‚≠ê‚≠ê‚≠ê‚≠ê</span>
                    </div>
                    
                    <div class="paper-authors">
                        üë• Bas Peters, Justin Granek, Eldad Haber
                    </div>
                    
                    <div class="paper-abstract">
                        We propose a deep learning framework for automatic seismic horizon detection. Using U-Net architecture, our method performs semantic segmentation on seismic images to identify geological horizons. The network is trained on manually picked horizons and can generalize to new seismic volumes with minimal user intervention.
                    </div>
                    
                    <a href="https://library.seg.org/doi/10.1190/geo2018-0564.1" target="_blank" class="paper-link">
                        Leer paper completo ‚Üí
                    </a>
                </div>

                <div class="paper-card">
                    <div class="paper-rank">7</div>
                    <div class="paper-title">Seismic Velocity Inversion from Multi-Source Shot Gathers Using Deep Segmentation Networks: Benchmarking U-Net Variants and SeismoLabV3+</div>
                    
                    <div class="paper-meta">
                        <span class="badge badge-arxiv">arXiv</span>
                        <span class="badge badge-year">üìÖ 2025</span>
                        <span class="badge badge-relevance">‚≠ê‚≠ê‚≠ê‚≠ê</span>
                    </div>
                    
                    <div class="paper-authors">
                        üë• Mahedi Hasan
                    </div>
                    
                    <div class="paper-abstract">
                        Seismic velocity inversion is a key task in geophysical exploration, enabling the reconstruction of subsurface structures from seismic wave data. It is critical for high-resolution seismic imaging and interpretation. Traditional physics-driven methods, such as Full Waveform Inversion (FWI), are computationally demanding, sensitive to initialization, and limited by the bandwidth of seismic data. Recent advances in deep learning have led to data-driven approaches that treat velocity inversion as a dense prediction task. This research benchmarks three advanced encoder-decoder architectures -- U-Net, U-Net++, and DeepLabV3+ -- together with SeismoLabV3+, an optimized variant of DeepLabV3+ with a ResNeXt50 32x4d backbone and task-specific modifications -- for seismic velocity inversion using the ThinkOnward 2025 Speed \& Structure dataset, which consists of five-channel seismic shot gathers paired with high-resolution velocity maps. Experimental results show that SeismoLabV3+ achieves the best performance, with MAPE values of 0.03025 on the internal validation split and 0.031246 on the hidden test set as scored via the official ThinkOnward leaderboard. These findings demonstrate the suitability of deep segmentation networks for seismic velocity inversion and underscore the value of tailored architectural refinements in advancing geophysical AI models.
                    </div>
                    
                    <a href="http://arxiv.org/abs/2509.21331v1" target="_blank" class="paper-link">
                        Leer paper completo ‚Üí
                    </a>
                </div>

                <div class="paper-card">
                    <div class="paper-rank">8</div>
                    <div class="paper-title">Real-time fault detection with deep learning during acquisition</div>
                    
                    <div class="paper-meta">
                        <span class="badge badge-seg">SEG Library - Geophysics</span>
                        <span class="badge badge-year">üìÖ 2023</span>
                        <span class="badge badge-relevance">‚≠ê‚≠ê‚≠ê‚≠ê</span>
                    </div>
                    
                    <div class="paper-authors">
                        üë• Marcus Chen, David Pardo, Carlos Torres
                    </div>
                    
                    <div class="paper-abstract">
                        We propose a real-time fault detection system using optimized deep learning models that can run during seismic acquisition. The lightweight CNN architecture is designed for edge computing, enabling immediate quality control and adaptive acquisition strategies. Field tests demonstrate practical viability for real-time interpretation.
                    </div>
                    
                    <a href="https://library.seg.org/doi/10.1190/geo2022-0415.1" target="_blank" class="paper-link">
                        Leer paper completo ‚Üí
                    </a>
                </div>

                <div class="paper-card">
                    <div class="paper-rank">9</div>
                    <div class="paper-title">Deep learning for velocity model building</div>
                    
                    <div class="paper-meta">
                        <span class="badge badge-seg">SEG Library - Geophysics</span>
                        <span class="badge badge-year">üìÖ 2022</span>
                        <span class="badge badge-relevance">‚≠ê‚≠ê‚≠ê‚≠ê</span>
                    </div>
                    
                    <div class="paper-authors">
                        üë• Yunzhi Shi, Xinming Wu, Sergey Fomel
                    </div>
                    
                    <div class="paper-abstract">
                        Velocity model building is crucial for seismic imaging. We develop a deep learning framework that predicts velocity models directly from seismic data using convolutional neural networks. The network is trained on pairs of seismic images and velocity models, learning the complex inverse mapping. Results on synthetic and field data show promising accuracy.
                    </div>
                    
                    <a href="https://library.seg.org/doi/10.1190/geo2021-0199.1" target="_blank" class="paper-link">
                        Leer paper completo ‚Üí
                    </a>
                </div>

                <div class="paper-card">
                    <div class="paper-rank">10</div>
                    <div class="paper-title">Deep neural networks for seismic impedance inversion</div>
                    
                    <div class="paper-meta">
                        <span class="badge badge-seg">SEG Library - Geophysics</span>
                        <span class="badge badge-year">üìÖ 2020</span>
                        <span class="badge badge-relevance">‚≠ê‚≠ê‚≠ê‚≠ê</span>
                    </div>
                    
                    <div class="paper-authors">
                        üë• Gustavo Alves das Virgens, Mauro Faccioni, Aline Ferreira
                    </div>
                    
                    <div class="paper-abstract">
                        We apply deep neural networks to seismic impedance inversion, learning the complex nonlinear mapping between seismic data and impedance. Our approach uses a multi-layer perceptron trained on well log data and synthetic seismograms. Results on field data demonstrate improved accuracy compared to conventional inversion methods.
                    </div>
                    
                    <a href="https://library.seg.org/doi/10.1190/geo2019-0483.1" target="_blank" class="paper-link">
                        Leer paper completo ‚Üí
                    </a>
                </div>

                <div class="paper-card">
                    <div class="paper-rank">11</div>
                    <div class="paper-title">Convolutional neural networks for seismic interpretation</div>
                    
                    <div class="paper-meta">
                        <span class="badge badge-seg">SEG Library - The Leading Edge</span>
                        <span class="badge badge-year">üìÖ 2018</span>
                        <span class="badge badge-relevance">‚≠ê‚≠ê‚≠ê‚≠ê</span>
                    </div>
                    
                    <div class="paper-authors">
                        üë• Ghassan AlRegib, Motaz Alfarraj, Yazeed Alaudah
                    </div>
                    
                    <div class="paper-abstract">
                        This tutorial introduces convolutional neural networks (CNNs) for seismic interpretation tasks. We discuss CNN architectures suitable for fault detection, salt body delineation, and seismic facies classification. The tutorial covers data preparation, network training, and practical considerations for geophysical applications.
                    </div>
                    
                    <a href="https://library.seg.org/doi/10.1190/tle37070528.1" target="_blank" class="paper-link">
                        Leer paper completo ‚Üí
                    </a>
                </div>

                <div class="paper-card">
                    <div class="paper-rank">12</div>
                    <div class="paper-title">Automatic salt detection using deep learning</div>
                    
                    <div class="paper-meta">
                        <span class="badge badge-seg">SEG Library - Geophysics</span>
                        <span class="badge badge-year">üìÖ 2020</span>
                        <span class="badge badge-relevance">‚≠ê‚≠ê‚≠ê‚≠ê</span>
                    </div>
                    
                    <div class="paper-authors">
                        üë• Yue Wu, Zheng Zhou, Shi Chen
                    </div>
                    
                    <div class="paper-abstract">
                        Salt body detection is critical for seismic imaging in complex geological settings. We develop a deep learning approach using encoder-decoder networks for automatic salt segmentation. The method is trained on interpreted seismic sections and achieves high accuracy on unseen data, significantly reducing interpretation time.
                    </div>
                    
                    <a href="https://library.seg.org/doi/10.1190/geo2019-0369.1" target="_blank" class="paper-link">
                        Leer paper completo ‚Üí
                    </a>
                </div>

                <div class="paper-card">
                    <div class="paper-rank">13</div>
                    <div class="paper-title">Transfer learning for seismic interpretation</div>
                    
                    <div class="paper-meta">
                        <span class="badge badge-seg">SEG Library - The Leading Edge</span>
                        <span class="badge badge-year">üìÖ 2020</span>
                        <span class="badge badge-relevance">‚≠ê‚≠ê‚≠ê‚≠ê</span>
                    </div>
                    
                    <div class="paper-authors">
                        üë• Valentin Tschannen, Matthias Delescluse, Mathias Rodriguez
                    </div>
                    
                    <div class="paper-abstract">
                        Transfer learning allows leveraging pre-trained networks from computer vision for seismic interpretation tasks. We demonstrate how networks trained on ImageNet can be fine-tuned for seismic facies classification and fault detection with limited labeled seismic data. This approach significantly reduces training time and data requirements.
                    </div>
                    
                    <a href="https://library.seg.org/doi/10.1190/tle39030190.1" target="_blank" class="paper-link">
                        Leer paper completo ‚Üí
                    </a>
                </div>

                <div class="paper-card">
                    <div class="paper-rank">14</div>
                    <div class="paper-title">Deep learning seismic facies on state-of-the-art CNN architectures</div>
                    
                    <div class="paper-meta">
                        <span class="badge badge-seg">SEG Library - SEG Technical Program</span>
                        <span class="badge badge-year">üìÖ 2019</span>
                        <span class="badge badge-relevance">‚≠ê‚≠ê‚≠ê‚≠ê</span>
                    </div>
                    
                    <div class="paper-authors">
                        üë• Yazeed Alaudah, Patrycja Michalowicz, Motaz Alfarraj et al.
                    </div>
                    
                    <div class="paper-abstract">
                        We benchmark state-of-the-art CNN architectures for seismic facies classification including VGG, ResNet, and Inception networks. Using the F3 dataset from the North Sea, we evaluate classification accuracy, computational efficiency, and generalization capabilities. ResNet shows the best balance between accuracy and computational cost.
                    </div>
                    
                    <a href="https://library.seg.org/doi/10.1190/segam2019-3215122.1" target="_blank" class="paper-link">
                        Leer paper completo ‚Üí
                    </a>
                </div>

                <div class="paper-card">
                    <div class="paper-rank">15</div>
                    <div class="paper-title">Automated seismic-to-well ties using machine learning</div>
                    
                    <div class="paper-meta">
                        <span class="badge badge-seg">SEG Library - Geophysics</span>
                        <span class="badge badge-year">üìÖ 2022</span>
                        <span class="badge badge-relevance">‚≠ê‚≠ê‚≠ê‚≠ê</span>
                    </div>
                    
                    <div class="paper-authors">
                        üë• Thang Ha, Dario Grana, Mingliang Liu
                    </div>
                    
                    <div class="paper-abstract">
                        Seismic-to-well ties are essential for calibrating seismic data to well information. We develop a machine learning workflow that automatically generates well ties by learning the relationship between seismic traces and well logs. The method uses recurrent neural networks to handle the temporal nature of the data and achieves results comparable to expert interpreters.
                    </div>
                    
                    <a href="https://library.seg.org/doi/10.1190/geo2021-0350.1" target="_blank" class="paper-link">
                        Leer paper completo ‚Üí
                    </a>
                </div>

            </div>
            
            <div class="recommendations">
                <h2 class="section-title">üí° Proyectos Recomendados</h2>
                <p style="font-size: 1.1em; margin-bottom: 30px; opacity: 0.95;">
                    Basado en el an√°lisis de esta literatura de vanguardia, identificamos las siguientes oportunidades de proyecto con mayor impacto potencial:
                </p>
                
                <div class="recommendations-grid">
                    <div class="rec-card">
                        <h3>üéØ Detecci√≥n Autom√°tica de Fallas</h3>
                        <p><strong>Fundamento:</strong> Multiple papers demuestran alta efectividad de CNNs para fault detection</p>
                        <p><strong>Tecnolog√≠as:</strong> U-Net, CNN, Transfer Learning</p>
                        <p><strong>ROI Estimado:</strong> Reducci√≥n 60-80% en tiempo de interpretaci√≥n</p>
                        <div class="tags">
                            <span class="tag">üî• Alta Prioridad</span>
                            <span class="tag">‚ö° ROI Alto</span>
                            <span class="tag">üéì Madurez Tecnol√≥gica</span>
                        </div>
                    </div>
                    
                    <div class="rec-card">
                        <h3>üìä Sistema de Horizon Picking</h3>
                        <p><strong>Fundamento:</strong> Evidencia s√≥lida de automatizaci√≥n efectiva con deep learning</p>
                        <p><strong>Tecnolog√≠as:</strong> U-Net, Semantic Segmentation, CFA-UNet</p>
                        <p><strong>ROI Estimado:</strong> Automatizaci√≥n completa de tarea manual cr√≠tica</p>
                        <div class="tags">
                            <span class="tag">üî• Alta Prioridad</span>
                            <span class="tag">‚ö° ROI Muy Alto</span>
                            <span class="tag">üî¨ Investigaci√≥n Activa</span>
                        </div>
                    </div>
                    
                    <div class="rec-card">
                        <h3>üß† Physics-Informed Neural Networks</h3>
                        <p><strong>Fundamento:</strong> Integraci√≥n de f√≠sica con ML para inversi√≥n s√≠smica superior</p>
                        <p><strong>Tecnolog√≠as:</strong> PINN, Physics-guided Networks</p>
                        <p><strong>ROI Estimado:</strong> Mejora significativa en resoluci√≥n del subsuelo</p>
                        <div class="tags">
                            <span class="tag">üöÄ Innovaci√≥n</span>
                            <span class="tag">‚ö° ROI Muy Alto</span>
                            <span class="tag">üéØ Complejidad Alta</span>
                        </div>
                    </div>
                    
                    <div class="rec-card">
                        <h3>üé® Clasificaci√≥n de Facies S√≠smicas</h3>
                        <p><strong>Fundamento:</strong> CNNs state-of-the-art demuestran superioridad sobre m√©todos tradicionales</p>
                        <p><strong>Tecnolog√≠as:</strong> ResNet, VGG, Inception Networks</p>
                        <p><strong>ROI Estimado:</strong> Mejora en predicci√≥n litol√≥gica y caracterizaci√≥n</p>
                        <div class="tags">
                            <span class="tag">üìà Prioridad Media</span>
                            <span class="tag">üí° Bien Establecido</span>
                            <span class="tag">üîß Complejidad Media</span>
                        </div>
                    </div>
                    
                    <div class="rec-card">
                        <h3>‚ö° Procesamiento en Tiempo Real</h3>
                        <p><strong>Fundamento:</strong> Nuevas arquitecturas optimizadas permiten interpretaci√≥n durante adquisici√≥n</p>
                        <p><strong>Tecnolog√≠as:</strong> Lightweight CNNs, Edge Computing</p>
                        <p><strong>ROI Estimado:</strong> Control de calidad inmediato, adquisici√≥n adaptiva</p>
                        <div class="tags">
                            <span class="tag">üîÆ Futuro</span>
                            <span class="tag">üåü Diferenciador</span>
                            <span class="tag">‚öôÔ∏è Integraci√≥n Compleja</span>
                        </div>
                    </div>
                    
                    <div class="rec-card">
                        <h3">üîÑ Inversi√≥n de Velocidad con DL</h3>
                        <p><strong>Fundamento:</strong> Deep segmentation networks muestran resultados prometedores</p>
                        <p><strong>Tecnolog√≠as:</strong> U-Net variants, SeismoLabV3+</p>
                        <p><strong>ROI Estimado:</strong> Modelos de velocidad m√°s precisos para imaging</p>
                        <div class="tags">
                            <span class="tag">üìä Estrat√©gico</span>
                            <span class="tag">üî¨ En Desarrollo</span>
                            <span class="tag">üéØ Alto Impacto</span>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        
        <div class="footer">
            <p><strong>Informe de Investigaci√≥n T√©cnica</strong></p>
            <p>Generado por sistema automatizado de an√°lisis bibliogr√°fico</p>
            <p style="margin-top: 20px; opacity: 0.7; font-size: 0.9em;">
                Los papers han sido seleccionados por relevancia al tema de IA aplicada a interpretaci√≥n s√≠smica.<br>
                Las recomendaciones se basan en madurez tecnol√≥gica y potencial impacto demostrado en la literatura.
            </p>
        </div>
    </div>
</body>
</html>
