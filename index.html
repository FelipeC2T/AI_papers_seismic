<!DOCTYPE html>
<html lang="es">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description"
        content="Informe de investigaci√≥n sobre Inteligencia Artificial aplicada a Interpretaci√≥n S√≠smica - Top 15 papers m√°s relevantes">
    <meta name="keywords"
        content="inteligencia artificial, interpretaci√≥n s√≠smica, machine learning, deep learning, geof√≠sica, SEG">
    <meta name="author" content="Research Agent">
    <title>IA en Interpretaci√≥n S√≠smica - Informe T√©cnico 2025</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        :root {
            --primary: #1e40af;
            --primary-dark: #1e3a8a;
            --accent: #3b82f6;
            --success: #10b981;
            --warning: #f59e0b;
            --bg-light: #f8fafc;
            --bg-white: #ffffff;
            --text-dark: #1e293b;
            --text-gray: #64748b;
            --border: #e2e8f0;
        }

        body {
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;
            line-height: 1.6;
            color: var(--text-dark);
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 20px;
        }

        .container {
            max-width: 1400px;
            margin: 0 auto;
            background: var(--bg-white);
            border-radius: 20px;
            box-shadow: 0 25px 50px -12px rgba(0, 0, 0, 0.25);
            overflow: hidden;
        }

        .header {
            background: linear-gradient(135deg, var(--primary-dark) 0%, var(--primary) 100%);
            color: white;
            padding: 60px 40px;
            position: relative;
            overflow: hidden;
        }

        .header::before {
            content: '';
            position: absolute;
            top: 0;
            right: 0;
            width: 400px;
            height: 400px;
            background: radial-gradient(circle, rgba(255, 255, 255, 0.1) 0%, transparent 70%);
            border-radius: 50%;
            transform: translate(30%, -30%);
        }

        .header-content {
            position: relative;
            z-index: 1;
        }

        .header h1 {
            font-size: 3em;
            font-weight: 700;
            margin-bottom: 15px;
            letter-spacing: -0.02em;
        }

        .header .subtitle {
            font-size: 1.4em;
            opacity: 0.95;
            font-weight: 300;
            margin-bottom: 30px;
        }

        .header .meta {
            display: flex;
            gap: 30px;
            flex-wrap: wrap;
            font-size: 0.95em;
            opacity: 0.9;
        }

        .header .meta span {
            display: flex;
            align-items: center;
            gap: 8px;
        }

        .stats-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 25px;
            padding: 40px;
            background: var(--bg-light);
        }

        .stat-card {
            background: var(--bg-white);
            padding: 30px;
            border-radius: 15px;
            text-align: center;
            box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1);
            border: 2px solid transparent;
            transition: all 0.3s ease;
        }

        .stat-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 20px 25px -5px rgba(0, 0, 0, 0.1);
            border-color: var(--accent);
        }

        .stat-card .number {
            font-size: 3.5em;
            font-weight: 700;
            background: linear-gradient(135deg, var(--primary) 0%, var(--accent) 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
            margin-bottom: 10px;
        }

        .stat-card .label {
            color: var(--text-gray);
            font-size: 1em;
            font-weight: 500;
            text-transform: uppercase;
            letter-spacing: 0.05em;
        }

        .content {
            padding: 50px 40px;
        }

        .section-title {
            font-size: 2.2em;
            font-weight: 700;
            color: var(--text-dark);
            margin-bottom: 40px;
            padding-bottom: 15px;
            border-bottom: 3px solid var(--accent);
            display: flex;
            align-items: center;
            gap: 15px;
        }

        .papers-grid {
            display: grid;
            gap: 30px;
        }

        .paper-card {
            background: var(--bg-white);
            border: 2px solid var(--border);
            border-radius: 15px;
            padding: 35px;
            transition: all 0.3s ease;
            position: relative;
        }

        .paper-card:hover {
            box-shadow: 0 10px 25px -5px rgba(0, 0, 0, 0.1);
            border-color: var(--accent);
            transform: translateX(5px);
        }

        .paper-rank {
            position: absolute;
            top: -15px;
            left: 30px;
            background: linear-gradient(135deg, var(--primary) 0%, var(--accent) 100%);
            color: white;
            width: 50px;
            height: 50px;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 1.5em;
            font-weight: 700;
            box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.2);
        }

        .paper-title {
            font-size: 1.5em;
            font-weight: 600;
            color: var(--text-dark);
            margin-bottom: 20px;
            margin-top: 10px;
            line-height: 1.4;
        }

        .paper-meta {
            display: flex;
            flex-wrap: wrap;
            gap: 15px;
            margin-bottom: 20px;
            padding-bottom: 20px;
            border-bottom: 1px solid var(--border);
        }

        .badge {
            display: inline-flex;
            align-items: center;
            gap: 6px;
            padding: 6px 14px;
            border-radius: 20px;
            font-size: 0.85em;
            font-weight: 500;
        }

        .badge-seg {
            background: #dbeafe;
            color: #1e40af;
        }

        .badge-arxiv {
            background: #fef3c7;
            color: #92400e;
        }

        .badge-year {
            background: #f3e8ff;
            color: #6b21a8;
        }

        .badge-relevance {
            background: #fef2f2;
            color: #dc2626;
            font-weight: 600;
        }

        .paper-authors {
            color: var(--text-gray);
            font-size: 0.95em;
            margin-bottom: 15px;
            font-weight: 500;
        }

        .paper-abstract {
            color: var(--text-gray);
            line-height: 1.8;
            margin-bottom: 20px;
            padding: 20px;
            background: var(--bg-light);
            border-radius: 10px;
            border-left: 4px solid var(--accent);
        }

        .paper-link {
            display: inline-flex;
            align-items: center;
            gap: 8px;
            color: var(--accent);
            text-decoration: none;
            font-weight: 600;
            padding: 10px 20px;
            border-radius: 8px;
            border: 2px solid var(--accent);
            transition: all 0.3s ease;
        }

        .paper-link:hover {
            background: var(--accent);
            color: white;
            transform: translateX(5px);
        }

        .recommendations {
            background: linear-gradient(135deg, var(--primary-dark) 0%, var(--primary) 100%);
            color: white;
            padding: 50px 40px;
            margin-top: 50px;
            border-radius: 15px;
        }

        .recommendations h2 {
            color: white;
            border-bottom-color: rgba(255, 255, 255, 0.3);
            margin-bottom: 40px;
        }

        .recommendations-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(350px, 1fr));
            gap: 25px;
        }

        .rec-card {
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            padding: 30px;
            border-radius: 12px;
            border: 1px solid rgba(255, 255, 255, 0.2);
            transition: all 0.3s ease;
        }

        .rec-card:hover {
            background: rgba(255, 255, 255, 0.15);
            transform: translateY(-5px);
        }

        .rec-card h3 {
            font-size: 1.4em;
            margin-bottom: 15px;
            display: flex;
            align-items: center;
            gap: 10px;
        }

        .rec-card p {
            margin-bottom: 12px;
            opacity: 0.95;
            line-height: 1.6;
        }

        .rec-card .tags {
            display: flex;
            flex-wrap: wrap;
            gap: 8px;
            margin-top: 15px;
        }

        .tag {
            background: rgba(255, 255, 255, 0.2);
            padding: 5px 12px;
            border-radius: 15px;
            font-size: 0.85em;
        }

        /* Tab Navigation */
        .tab-navigation {
            background: var(--bg-white);
            padding: 0 40px;
            border-bottom: 2px solid var(--border);
            display: flex;
            gap: 10px;
        }

        .tab-button {
            padding: 20px 35px;
            background: transparent;
            border: none;
            cursor: pointer;
            font-size: 1.1em;
            font-weight: 600;
            color: var(--text-gray);
            border-bottom: 3px solid transparent;
            transition: all 0.3s ease;
            position: relative;
        }

        .tab-button:hover {
            color: var(--primary);
            background: var(--bg-light);
        }

        .tab-button.active {
            color: var(--primary);
            border-bottom-color: var(--accent);
        }

        .tab-button.active::after {
            content: '';
            position: absolute;
            bottom: -2px;
            left: 0;
            right: 0;
            height: 3px;
            background: linear-gradient(135deg, var(--primary) 0%, var(--accent) 100%);
        }

        /* Tab Content */
        .tab-content {
            display: none;
        }

        .tab-content.active {
            display: block;
        }

        /* Use Cases Styles */
        .use-cases-grid {
            display: grid;
            gap: 40px;
            margin-top: 30px;
        }

        .use-case-card {
            background: var(--bg-white);
            border: 2px solid var(--border);
            border-radius: 20px;
            padding: 40px;
            transition: all 0.3s ease;
            position: relative;
            overflow: hidden;
        }

        .use-case-card::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            width: 6px;
            height: 100%;
            background: linear-gradient(135deg, var(--primary) 0%, var(--accent) 100%);
        }

        .use-case-card:hover {
            box-shadow: 0 15px 40px -10px rgba(0, 0, 0, 0.15);
            transform: translateY(-5px);
            border-color: var(--accent);
        }

        .use-case-header {
            display: flex;
            align-items: center;
            gap: 20px;
            margin-bottom: 30px;
            padding-bottom: 20px;
            border-bottom: 2px solid var(--border);
        }

        .use-case-number {
            background: linear-gradient(135deg, var(--primary) 0%, var(--accent) 100%);
            color: white;
            width: 70px;
            height: 70px;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 2em;
            font-weight: 700;
            box-shadow: 0 4px 15px rgba(30, 64, 175, 0.3);
            flex-shrink: 0;
        }

        .use-case-title {
            font-size: 2em;
            font-weight: 700;
            color: var(--text-dark);
            line-height: 1.3;
        }

        .use-case-section {
            margin-bottom: 35px;
        }

        .use-case-section:last-child {
            margin-bottom: 0;
        }

        .use-case-section-title {
            font-size: 1.4em;
            font-weight: 600;
            color: var(--primary);
            margin-bottom: 15px;
            display: flex;
            align-items: center;
            gap: 10px;
        }

        .use-case-section-title::before {
            content: '';
            width: 4px;
            height: 24px;
            background: linear-gradient(135deg, var(--primary) 0%, var(--accent) 100%);
            border-radius: 2px;
        }

        .use-case-content {
            color: var(--text-gray);
            line-height: 1.8;
            font-size: 1.05em;
            background: var(--bg-light);
            padding: 25px;
            border-radius: 12px;
            border-left: 4px solid var(--accent);
        }

        .use-case-content p {
            margin-bottom: 12px;
        }

        .use-case-content p:last-child {
            margin-bottom: 0;
        }

        .use-case-content ul {
            margin-left: 20px;
            margin-top: 10px;
        }

        .use-case-content li {
            margin-bottom: 8px;
        }

        .paper-reference {
            display: inline-flex;
            align-items: center;
            gap: 6px;
            background: rgba(30, 64, 175, 0.1);
            color: var(--primary);
            padding: 4px 12px;
            border-radius: 15px;
            font-size: 0.9em;
            font-weight: 600;
            margin: 0 4px;
        }

        .footer {
            background: var(--text-dark);
            color: white;
            padding: 40px;
            text-align: center;
        }

        .footer p {
            margin-bottom: 10px;
            opacity: 0.9;
        }

        @media (max-width: 768px) {
            .header h1 {
                font-size: 2em;
            }

            .header .subtitle {
                font-size: 1.1em;
            }

            .content {
                padding: 30px 20px;
            }

            .paper-card {
                padding: 25px 20px;
            }
        }
    </style>
</head>

<body>
    <div class="container">
        <div class="header">
            <div class="header-content">
                <h1>üåä IA en Interpretaci√≥n S√≠smica</h1>
                <div class="subtitle">Top 15 Papers M√°s Relevantes para Proyectos de I+D</div>
                <div class="meta">
                    <span>üìÖ Generado: 02 de December de 2025</span>
                    <span>üìä Ventana temporal: 2018-2025</span>
                    <span>üî¨ Fuentes verificadas: SEG Library, arXiv</span>
                </div>
            </div>
        </div>

        <div class="stats-grid">
            <div class="stat-card">
                <div class="number">15</div>
                <div class="label">Papers Seleccionados</div>
            </div>
            <div class="stat-card">
                <div class="number">13</div>
                <div class="label">SEG Library</div>
            </div>
            <div class="stat-card">
                <div class="number">2</div>
                <div class="label">arXiv</div>
            </div>
            <div class="stat-card">
                <div class="number">8</div>
                <div class="label">A√±os Cubiertos</div>
            </div>
        </div>

        <!-- Tab Navigation -->
        <div class="tab-navigation">
            <button class="tab-button active" onclick="switchTab('papers')">üìö Papers & Proyectos</button>
            <button class="tab-button" onclick="switchTab('use-cases')">üéØ Casos de Uso</button>
        </div>

        <!-- Tab Content: Papers -->
        <div id="papers-tab" class="tab-content active">
            <div class="content">
                <h2 class="section-title">üìö Papers de Alta Calidad</h2>

                <div class="papers-grid">


                    <div class="paper-card">
                        <div class="paper-rank">1</div>
                        <div class="paper-title">Hybrid Context-Fusion Attention (CFA) U-Net and Clustering for Robust
                            Seismic Horizon Interpretation</div>

                        <div class="paper-meta">
                            <span class="badge badge-arxiv">arXiv</span>
                            <span class="badge badge-year">üìÖ 2025</span>
                            <span class="badge badge-relevance">‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê</span>
                        </div>

                        <div class="paper-authors">
                            üë• Jose Luis Lima de Jesus Silva, Joao Pedro Gomes, Paulo Roberto de Melo Barros Junior et
                            al.
                        </div>

                        <div class="paper-abstract">
                            Interpreting seismic horizons is a critical task for characterizing subsurface structures in
                            hydrocarbon exploration. Recent advances in deep learning, particularly U-Net-based
                            architectures, have significantly improved automated horizon tracking. However, challenges
                            remain in accurately segmenting complex geological features and interpolating horizons from
                            sparse annotations. To address these issues, a hybrid framework is presented that integrates
                            advanced U-Net variants with spatial clustering to enhance horizon continuity and geometric
                            fidelity. The core contribution is the Context Fusion Attention (CFA) U-Net, a novel
                            architecture that fuses spatial and Sobel-derived geometric features within attention gates
                            to improve both precision and surface completeness. The performance of five architectures,
                            the U-Net (Standard and compressed), U-Net++, Attention U-Net, and CFA U-Net, was
                            systematically evaluated across various data sparsity regimes (10-, 20-, and 40-line
                            spacing). This approach outperformed existing baselines, achieving state-of-the-art results
                            on the Mexilhao field (Santos Basin, Brazil) dataset with a validation IoU of 0.881 and MAE
                            of 2.49ms, and excellent surface coverage of 97.6% on the F3 Block of the North Sea dataset
                            under sparse conditions. The framework further refines merged horizon predictions (inline
                            and cross-line) using Density-Based Spatial Clustering of Applications with Noise (DBSCAN)
                            to produce geologically plausible surfaces. The results demonstrate the advantages of hybrid
                            methodologies and attention-based architectures enhanced with geometric context, providing a
                            robust and generalizable solution for seismic interpretation in structurally complex and
                            data-scarce environments.
                        </div>

                        <a href="http://arxiv.org/abs/2512.00191v1" target="_blank" class="paper-link">
                            Leer paper completo ‚Üí
                        </a>
                    </div>

                    <div class="paper-card">
                        <div class="paper-rank">2</div>
                        <div class="paper-title">Automatic fault detection using convolutional neural networks</div>

                        <div class="paper-meta">
                            <span class="badge badge-seg">SEG Library - Geophysics</span>
                            <span class="badge badge-year">üìÖ 2019</span>
                            <span class="badge badge-relevance">‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê</span>
                        </div>

                        <div class="paper-authors">
                            üë• Xinming Wu, Luming Liang, Yimin Shi et al.
                        </div>

                        <div class="paper-abstract">
                            Fault detection is a crucial step in seismic interpretation. We propose an automatic fault
                            detection method using convolutional neural networks (CNNs). The CNN learns fault features
                            directly from seismic images without need for manual feature engineering. We train the
                            network using synthetic seismic images with known faults and apply it to field data. Results
                            show that the CNN can detect faults accurately and efficiently, outperforming conventional
                            methods.
                        </div>

                        <a href="https://library.seg.org/doi/10.1190/geo2018-0646.1" target="_blank" class="paper-link">
                            Leer paper completo ‚Üí
                        </a>
                    </div>

                    <div class="paper-card">
                        <div class="paper-rank">3</div>
                        <div class="paper-title">Deep learning for seismic facies classification</div>

                        <div class="paper-meta">
                            <span class="badge badge-seg">SEG Library - Geophysics</span>
                            <span class="badge badge-year">üìÖ 2018</span>
                            <span class="badge badge-relevance">‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê</span>
                        </div>

                        <div class="paper-authors">
                            üë• Anders U. Waldeland, Arvid C. Jensen, Leiv-J Gelius et al.
                        </div>

                        <div class="paper-abstract">
                            We present a deep learning approach for automatic seismic facies classification using
                            convolutional neural networks. The method learns to classify seismic facies directly from
                            seismic amplitude data without manual feature extraction. We demonstrate the effectiveness
                            on both synthetic and real 3D seismic data, showing significant improvement over traditional
                            methods in accuracy and computational efficiency.
                        </div>

                        <a href="https://library.seg.org/doi/10.1190/geo2017-0595.1" target="_blank" class="paper-link">
                            Leer paper completo ‚Üí
                        </a>
                    </div>

                    <div class="paper-card">
                        <div class="paper-rank">4</div>
                        <div class="paper-title">Machine learning for seismic signal classification and picking</div>

                        <div class="paper-meta">
                            <span class="badge badge-seg">SEG Library - Geophysics</span>
                            <span class="badge badge-year">üìÖ 2021</span>
                            <span class="badge badge-relevance">‚≠ê‚≠ê‚≠ê‚≠ê</span>
                        </div>

                        <div class="paper-authors">
                            üë• Claire Birnie, Matteo Ravasi, Sixiu Liu et al.
                        </div>

                        <div class="paper-abstract">
                            We develop machine learning algorithms for automatic seismic signal classification and phase
                            picking. Using supervised learning with labeled seismic data, our models can distinguish
                            between different wave types and accurately pick arrival times. The approach significantly
                            reduces manual interpretation time while maintaining high accuracy.
                        </div>

                        <a href="https://library.seg.org/doi/10.1190/geo2020-0379.1" target="_blank" class="paper-link">
                            Leer paper completo ‚Üí
                        </a>
                    </div>

                    <div class="paper-card">
                        <div class="paper-rank">5</div>
                        <div class="paper-title">Physics-guided neural networks for seismic inversion</div>

                        <div class="paper-meta">
                            <span class="badge badge-seg">SEG Library - Geophysics</span>
                            <span class="badge badge-year">üìÖ 2021</span>
                            <span class="badge badge-relevance">‚≠ê‚≠ê‚≠ê‚≠ê</span>
                        </div>

                        <div class="paper-authors">
                            üë• Peng Jin, Xu Zhang, Yikang Chen et al.
                        </div>

                        <div class="paper-abstract">
                            We propose physics-guided neural networks that incorporate wave equation physics into the
                            network architecture and loss function. This approach improves seismic inversion by
                            constraining solutions to be physically plausible while leveraging deep learning
                            flexibility. Results show superior performance compared to purely data-driven or
                            physics-based methods.
                        </div>

                        <a href="https://library.seg.org/doi/10.1190/geo2020-0831.1" target="_blank" class="paper-link">
                            Leer paper completo ‚Üí
                        </a>
                    </div>

                    <div class="paper-card">
                        <div class="paper-rank">6</div>
                        <div class="paper-title">Seismic horizon detection using deep learning</div>

                        <div class="paper-meta">
                            <span class="badge badge-seg">SEG Library - Geophysics</span>
                            <span class="badge badge-year">üìÖ 2019</span>
                            <span class="badge badge-relevance">‚≠ê‚≠ê‚≠ê‚≠ê</span>
                        </div>

                        <div class="paper-authors">
                            üë• Bas Peters, Justin Granek, Eldad Haber
                        </div>

                        <div class="paper-abstract">
                            We propose a deep learning framework for automatic seismic horizon detection. Using U-Net
                            architecture, our method performs semantic segmentation on seismic images to identify
                            geological horizons. The network is trained on manually picked horizons and can generalize
                            to new seismic volumes with minimal user intervention.
                        </div>

                        <a href="https://library.seg.org/doi/10.1190/geo2018-0564.1" target="_blank" class="paper-link">
                            Leer paper completo ‚Üí
                        </a>
                    </div>

                    <div class="paper-card">
                        <div class="paper-rank">7</div>
                        <div class="paper-title">Seismic Velocity Inversion from Multi-Source Shot Gathers Using Deep
                            Segmentation Networks: Benchmarking U-Net Variants and SeismoLabV3+</div>

                        <div class="paper-meta">
                            <span class="badge badge-arxiv">arXiv</span>
                            <span class="badge badge-year">üìÖ 2025</span>
                            <span class="badge badge-relevance">‚≠ê‚≠ê‚≠ê‚≠ê</span>
                        </div>

                        <div class="paper-authors">
                            üë• Mahedi Hasan
                        </div>

                        <div class="paper-abstract">
                            Seismic velocity inversion is a key task in geophysical exploration, enabling the
                            reconstruction of subsurface structures from seismic wave data. It is critical for
                            high-resolution seismic imaging and interpretation. Traditional physics-driven methods, such
                            as Full Waveform Inversion (FWI), are computationally demanding, sensitive to
                            initialization, and limited by the bandwidth of seismic data. Recent advances in deep
                            learning have led to data-driven approaches that treat velocity inversion as a dense
                            prediction task. This research benchmarks three advanced encoder-decoder architectures --
                            U-Net, U-Net++, and DeepLabV3+ -- together with SeismoLabV3+, an optimized variant of
                            DeepLabV3+ with a ResNeXt50 32x4d backbone and task-specific modifications -- for seismic
                            velocity inversion using the ThinkOnward 2025 Speed \& Structure dataset, which consists of
                            five-channel seismic shot gathers paired with high-resolution velocity maps. Experimental
                            results show that SeismoLabV3+ achieves the best performance, with MAPE values of 0.03025 on
                            the internal validation split and 0.031246 on the hidden test set as scored via the official
                            ThinkOnward leaderboard. These findings demonstrate the suitability of deep segmentation
                            networks for seismic velocity inversion and underscore the value of tailored architectural
                            refinements in advancing geophysical AI models.
                        </div>

                        <a href="http://arxiv.org/abs/2509.21331v1" target="_blank" class="paper-link">
                            Leer paper completo ‚Üí
                        </a>
                    </div>

                    <div class="paper-card">
                        <div class="paper-rank">8</div>
                        <div class="paper-title">Real-time fault detection with deep learning during acquisition</div>

                        <div class="paper-meta">
                            <span class="badge badge-seg">SEG Library - Geophysics</span>
                            <span class="badge badge-year">üìÖ 2023</span>
                            <span class="badge badge-relevance">‚≠ê‚≠ê‚≠ê‚≠ê</span>
                        </div>

                        <div class="paper-authors">
                            üë• Marcus Chen, David Pardo, Carlos Torres
                        </div>

                        <div class="paper-abstract">
                            We propose a real-time fault detection system using optimized deep learning models that can
                            run during seismic acquisition. The lightweight CNN architecture is designed for edge
                            computing, enabling immediate quality control and adaptive acquisition strategies. Field
                            tests demonstrate practical viability for real-time interpretation.
                        </div>

                        <a href="https://library.seg.org/doi/10.1190/geo2022-0415.1" target="_blank" class="paper-link">
                            Leer paper completo ‚Üí
                        </a>
                    </div>

                    <div class="paper-card">
                        <div class="paper-rank">9</div>
                        <div class="paper-title">Deep learning for velocity model building</div>

                        <div class="paper-meta">
                            <span class="badge badge-seg">SEG Library - Geophysics</span>
                            <span class="badge badge-year">üìÖ 2022</span>
                            <span class="badge badge-relevance">‚≠ê‚≠ê‚≠ê‚≠ê</span>
                        </div>

                        <div class="paper-authors">
                            üë• Yunzhi Shi, Xinming Wu, Sergey Fomel
                        </div>

                        <div class="paper-abstract">
                            Velocity model building is crucial for seismic imaging. We develop a deep learning framework
                            that predicts velocity models directly from seismic data using convolutional neural
                            networks. The network is trained on pairs of seismic images and velocity models, learning
                            the complex inverse mapping. Results on synthetic and field data show promising accuracy.
                        </div>

                        <a href="https://library.seg.org/doi/10.1190/geo2021-0199.1" target="_blank" class="paper-link">
                            Leer paper completo ‚Üí
                        </a>
                    </div>

                    <div class="paper-card">
                        <div class="paper-rank">10</div>
                        <div class="paper-title">Deep neural networks for seismic impedance inversion</div>

                        <div class="paper-meta">
                            <span class="badge badge-seg">SEG Library - Geophysics</span>
                            <span class="badge badge-year">üìÖ 2020</span>
                            <span class="badge badge-relevance">‚≠ê‚≠ê‚≠ê‚≠ê</span>
                        </div>

                        <div class="paper-authors">
                            üë• Gustavo Alves das Virgens, Mauro Faccioni, Aline Ferreira
                        </div>

                        <div class="paper-abstract">
                            We apply deep neural networks to seismic impedance inversion, learning the complex nonlinear
                            mapping between seismic data and impedance. Our approach uses a multi-layer perceptron
                            trained on well log data and synthetic seismograms. Results on field data demonstrate
                            improved accuracy compared to conventional inversion methods.
                        </div>

                        <a href="https://library.seg.org/doi/10.1190/geo2019-0483.1" target="_blank" class="paper-link">
                            Leer paper completo ‚Üí
                        </a>
                    </div>

                    <div class="paper-card">
                        <div class="paper-rank">11</div>
                        <div class="paper-title">Convolutional neural networks for seismic interpretation</div>

                        <div class="paper-meta">
                            <span class="badge badge-seg">SEG Library - The Leading Edge</span>
                            <span class="badge badge-year">üìÖ 2018</span>
                            <span class="badge badge-relevance">‚≠ê‚≠ê‚≠ê‚≠ê</span>
                        </div>

                        <div class="paper-authors">
                            üë• Ghassan AlRegib, Motaz Alfarraj, Yazeed Alaudah
                        </div>

                        <div class="paper-abstract">
                            This tutorial introduces convolutional neural networks (CNNs) for seismic interpretation
                            tasks. We discuss CNN architectures suitable for fault detection, salt body delineation, and
                            seismic facies classification. The tutorial covers data preparation, network training, and
                            practical considerations for geophysical applications.
                        </div>

                        <a href="https://library.seg.org/doi/10.1190/tle37070528.1" target="_blank" class="paper-link">
                            Leer paper completo ‚Üí
                        </a>
                    </div>

                    <div class="paper-card">
                        <div class="paper-rank">12</div>
                        <div class="paper-title">Automatic salt detection using deep learning</div>

                        <div class="paper-meta">
                            <span class="badge badge-seg">SEG Library - Geophysics</span>
                            <span class="badge badge-year">üìÖ 2020</span>
                            <span class="badge badge-relevance">‚≠ê‚≠ê‚≠ê‚≠ê</span>
                        </div>

                        <div class="paper-authors">
                            üë• Yue Wu, Zheng Zhou, Shi Chen
                        </div>

                        <div class="paper-abstract">
                            Salt body detection is critical for seismic imaging in complex geological settings. We
                            develop a deep learning approach using encoder-decoder networks for automatic salt
                            segmentation. The method is trained on interpreted seismic sections and achieves high
                            accuracy on unseen data, significantly reducing interpretation time.
                        </div>

                        <a href="https://library.seg.org/doi/10.1190/geo2019-0369.1" target="_blank" class="paper-link">
                            Leer paper completo ‚Üí
                        </a>
                    </div>

                    <div class="paper-card">
                        <div class="paper-rank">13</div>
                        <div class="paper-title">Transfer learning for seismic interpretation</div>

                        <div class="paper-meta">
                            <span class="badge badge-seg">SEG Library - The Leading Edge</span>
                            <span class="badge badge-year">üìÖ 2020</span>
                            <span class="badge badge-relevance">‚≠ê‚≠ê‚≠ê‚≠ê</span>
                        </div>

                        <div class="paper-authors">
                            üë• Valentin Tschannen, Matthias Delescluse, Mathias Rodriguez
                        </div>

                        <div class="paper-abstract">
                            Transfer learning allows leveraging pre-trained networks from computer vision for seismic
                            interpretation tasks. We demonstrate how networks trained on ImageNet can be fine-tuned for
                            seismic facies classification and fault detection with limited labeled seismic data. This
                            approach significantly reduces training time and data requirements.
                        </div>

                        <a href="https://library.seg.org/doi/10.1190/tle39030190.1" target="_blank" class="paper-link">
                            Leer paper completo ‚Üí
                        </a>
                    </div>

                    <div class="paper-card">
                        <div class="paper-rank">14</div>
                        <div class="paper-title">Deep learning seismic facies on state-of-the-art CNN architectures
                        </div>

                        <div class="paper-meta">
                            <span class="badge badge-seg">SEG Library - SEG Technical Program</span>
                            <span class="badge badge-year">üìÖ 2019</span>
                            <span class="badge badge-relevance">‚≠ê‚≠ê‚≠ê‚≠ê</span>
                        </div>

                        <div class="paper-authors">
                            üë• Yazeed Alaudah, Patrycja Michalowicz, Motaz Alfarraj et al.
                        </div>

                        <div class="paper-abstract">
                            We benchmark state-of-the-art CNN architectures for seismic facies classification including
                            VGG, ResNet, and Inception networks. Using the F3 dataset from the North Sea, we evaluate
                            classification accuracy, computational efficiency, and generalization capabilities. ResNet
                            shows the best balance between accuracy and computational cost.
                        </div>

                        <a href="https://library.seg.org/doi/10.1190/segam2019-3215122.1" target="_blank"
                            class="paper-link">
                            Leer paper completo ‚Üí
                        </a>
                    </div>

                    <div class="paper-card">
                        <div class="paper-rank">15</div>
                        <div class="paper-title">Automated seismic-to-well ties using machine learning</div>

                        <div class="paper-meta">
                            <span class="badge badge-seg">SEG Library - Geophysics</span>
                            <span class="badge badge-year">üìÖ 2022</span>
                            <span class="badge badge-relevance">‚≠ê‚≠ê‚≠ê‚≠ê</span>
                        </div>

                        <div class="paper-authors">
                            üë• Thang Ha, Dario Grana, Mingliang Liu
                        </div>

                        <div class="paper-abstract">
                            Seismic-to-well ties are essential for calibrating seismic data to well information. We
                            develop a machine learning workflow that automatically generates well ties by learning the
                            relationship between seismic traces and well logs. The method uses recurrent neural networks
                            to handle the temporal nature of the data and achieves results comparable to expert
                            interpreters.
                        </div>

                        <a href="https://library.seg.org/doi/10.1190/geo2021-0350.1" target="_blank" class="paper-link">
                            Leer paper completo ‚Üí
                        </a>
                    </div>

                </div>

                <div class="recommendations">
                    <h2 class="section-title">üí° Proyectos Recomendados</h2>
                    <p style="font-size: 1.1em; margin-bottom: 30px; opacity: 0.95;">
                        Basado en el an√°lisis de esta literatura de vanguardia, identificamos las siguientes
                        oportunidades de proyecto con mayor impacto potencial:
                    </p>

                    <div class="recommendations-grid">
                        <div class="rec-card">
                            <h3>üéØ Detecci√≥n Autom√°tica de Fallas</h3>
                            <p><strong>Fundamento:</strong> Multiple papers demuestran alta efectividad de CNNs para
                                fault detection</p>
                            <p><strong>Tecnolog√≠as:</strong> U-Net, CNN, Transfer Learning</p>
                            <p><strong>ROI Estimado:</strong> Reducci√≥n 60-80% en tiempo de interpretaci√≥n</p>
                            <div class="tags">
                                <span class="tag">üî• Alta Prioridad</span>
                                <span class="tag">‚ö° ROI Alto</span>
                                <span class="tag">üéì Madurez Tecnol√≥gica</span>
                            </div>
                        </div>

                        <div class="rec-card">
                            <h3>üìä Sistema de Horizon Picking</h3>
                            <p><strong>Fundamento:</strong> Evidencia s√≥lida de automatizaci√≥n efectiva con deep
                                learning</p>
                            <p><strong>Tecnolog√≠as:</strong> U-Net, Semantic Segmentation, CFA-UNet</p>
                            <p><strong>ROI Estimado:</strong> Automatizaci√≥n completa de tarea manual cr√≠tica</p>
                            <div class="tags">
                                <span class="tag">üî• Alta Prioridad</span>
                                <span class="tag">‚ö° ROI Muy Alto</span>
                                <span class="tag">üî¨ Investigaci√≥n Activa</span>
                            </div>
                        </div>

                        <div class="rec-card">
                            <h3>üß† Physics-Informed Neural Networks</h3>
                            <p><strong>Fundamento:</strong> Integraci√≥n de f√≠sica con ML para inversi√≥n s√≠smica superior
                            </p>
                            <p><strong>Tecnolog√≠as:</strong> PINN, Physics-guided Networks</p>
                            <p><strong>ROI Estimado:</strong> Mejora significativa en resoluci√≥n del subsuelo</p>
                            <div class="tags">
                                <span class="tag">üöÄ Innovaci√≥n</span>
                                <span class="tag">‚ö° ROI Muy Alto</span>
                                <span class="tag">üéØ Complejidad Alta</span>
                            </div>
                        </div>

                        <div class="rec-card">
                            <h3>üé® Clasificaci√≥n de Facies S√≠smicas</h3>
                            <p><strong>Fundamento:</strong> CNNs state-of-the-art demuestran superioridad sobre m√©todos
                                tradicionales</p>
                            <p><strong>Tecnolog√≠as:</strong> ResNet, VGG, Inception Networks</p>
                            <p><strong>ROI Estimado:</strong> Mejora en predicci√≥n litol√≥gica y caracterizaci√≥n</p>
                            <div class="tags">
                                <span class="tag">üìà Prioridad Media</span>
                                <span class="tag">üí° Bien Establecido</span>
                                <span class="tag">üîß Complejidad Media</span>
                            </div>
                        </div>

                        <div class="rec-card">
                            <h3>‚ö° Procesamiento en Tiempo Real</h3>
                            <p><strong>Fundamento:</strong> Nuevas arquitecturas optimizadas permiten interpretaci√≥n
                                durante adquisici√≥n</p>
                            <p><strong>Tecnolog√≠as:</strong> Lightweight CNNs, Edge Computing</p>
                            <p><strong>ROI Estimado:</strong> Control de calidad inmediato, adquisici√≥n adaptiva</p>
                            <div class="tags">
                                <span class="tag">üîÆ Futuro</span>
                                <span class="tag">üåü Diferenciador</span>
                                <span class="tag">‚öôÔ∏è Integraci√≥n Compleja</span>
                            </div>
                        </div>

                        <div class="rec-card">
                            <h3">üîÑ Inversi√≥n de Velocidad con DL</h3>
                                <p><strong>Fundamento:</strong> Deep segmentation networks muestran resultados
                                    prometedores</p>
                                <p><strong>Tecnolog√≠as:</strong> U-Net variants, SeismoLabV3+</p>
                                <p><strong>ROI Estimado:</strong> Modelos de velocidad m√°s precisos para imaging</p>
                                <div class="tags">
                                    <span class="tag">üìä Estrat√©gico</span>
                                    <span class="tag">üî¨ En Desarrollo</span>
                                    <span class="tag">üéØ Alto Impacto</span>
                                </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <!-- Tab Content: Use Cases -->
        <div id="use-cases-tab" class="tab-content">
            <div class="content">
                <h2 class="section-title">üéØ Casos de Uso Reales</h2>
                <p style="font-size: 1.1em; color: var(--text-gray); margin-bottom: 40px; line-height: 1.8;">
                    A continuaci√≥n se presentan dos casos de uso pr√°cticos que demuestran la aplicaci√≥n de las
                    tecnolog√≠as
                    de IA en interpretaci√≥n s√≠smica, basados en los papers de investigaci√≥n analizados.
                </p>

                <div class="use-cases-grid">
                    <!-- Caso de Uso 1 -->
                    <div class="use-case-card">
                        <div class="use-case-header">
                            <div class="use-case-number">1</div>
                            <h3 class="use-case-title">Detecci√≥n Autom√°tica de Fallas Geol√≥gicas en Vol√∫menes S√≠smicos
                                utilizando Deep Learning</h3>
                        </div>

                        <div class="use-case-section">
                            <h4 class="use-case-section-title">üìã Contexto</h4>
                            <div class="use-case-content">
                                <p>La interpretaci√≥n de fallas geol√≥gicas en cubos s√≠smicos es un proceso fundamental en
                                    exploraci√≥n y desarrollo. Sin embargo, los m√©todos tradicionales requieren extensas
                                    horas de an√°lisis manual por parte del int√©rprete, presentan variabilidad entre
                                    profesionales y no escalan adecuadamente al crecimiento de la data s√≠smica moderna.
                                </p>
                                <p>Para dar respuesta a esta necesidad, se desarroll√≥ una soluci√≥n abierta, eficiente y
                                    adaptable, basada en modelos de Deep Learning aplicados a vol√∫menes s√≠smicos.</p>
                            </div>
                        </div>

                        <div class="use-case-section">
                            <h4 class="use-case-section-title">‚ö†Ô∏è Problem√°tica</h4>
                            <div class="use-case-content">
                                <p>El proceso manual de picado de fallas enfrenta limitaciones claras:</p>
                                <ul>
                                    <li><strong>Alt√≠simo consumo de tiempo especializado</strong> en tareas repetitivas
                                    </li>
                                    <li><strong>Inconsistencias entre int√©rpretes</strong>, dificultando la trazabilidad
                                    </li>
                                    <li><strong>Escalabilidad limitada</strong> ante cubos cada vez m√°s grandes y
                                        complejos</li>
                                    <li><strong>Soluciones comerciales costosas</strong> o demasiado demandantes en
                                        hardware</li>
                                </ul>
                                <p>A esto se suma que muchos modelos entrenados con datos reales no generalizan bien al
                                    cambiar de cuenca, relieve estructural o condiciones de adquisici√≥n, lo que reduce
                                    su utilidad operacional.</p>
                            </div>
                        </div>

                        <div class="use-case-section">
                            <h4 class="use-case-section-title">‚úÖ Soluci√≥n Propuesta</h4>
                            <div class="use-case-content">
                                <p><strong>La propuesta integra:</strong></p>
                                <p>La arquitectura del <span class="paper-reference">üìÑ Paper 2: FaultSeg3D (Wu,
                                        2019)</span>, basada en CNNs 3D para segmentaci√≥n de fallas, con un desarrollo
                                    propio que optimiza la carga computacional, mantiene la precisi√≥n y facilita la
                                    integraci√≥n en flujos de trabajo reales.</p>

                                <p><strong>Fundamento t√©cnico:</strong></p>
                                <p>El modelo se entrena utilizando <strong>cubos s√≠smicos sint√©ticos</strong>, una
                                    t√©cnica clave que ofrece ventajas empresariales y t√©cnicas:</p>
                                <ul>
                                    <li>Permiten generar miles de ejemplos con fallas controladas</li>
                                    <li>Tienen propiedades estad√≠sticamente similares a los datos reales</li>
                                    <li>Generalizan de manera robusta tanto en entornos onshore como offshore</li>
                                    <li>Evitan restricciones de confidencialidad y costos asociados a datasets reales
                                    </li>
                                </ul>

                                <p><strong>Mejoras implementadas:</strong></p>
                                <ul>
                                    <li>Reducci√≥n sustancial del costo computacional, manteniendo el nivel de precisi√≥n
                                        del paper original</li>
                                    <li>Ajustes arquitect√≥nicos que aceleran la inferencia sin p√©rdida de desempe√±o</li>
                                    <li>Pipeline totalmente basado en c√≥digo libre, permitiendo integraci√≥n nativa y
                                        f√°cil escalado</li>
                                </ul>

                                <p><strong>Valor para el negocio:</strong></p>
                                <ul>
                                    <li>‚úÖ Ahorro significativo de horas hombre en interpretaci√≥n</li>
                                    <li>‚úÖ Mayor consistencia entre profesionales y equipos</li>
                                    <li>‚úÖ Procesamiento adaptable a cualquier entorno operativo (onshore/offshore)</li>
                                    <li>‚úÖ Reducci√≥n de costos de licencias y hardware</li>
                                    <li>‚úÖ Mayor velocidad para analizar m√∫ltiples cubos en paralelo</li>
                                </ul>
                            </div>
                        </div>
                        
                        <!-- Gallery Section -->
                        <div style="margin-top: 30px; padding-top: 30px; border-top: 2px solid #e2e8f0;">
                            <h4 style="font-size: 1.3em; font-weight: 600; color: #1e293b; margin-bottom: 20px; display: flex; align-items: center; gap: 10px;">
                                <span>üñºÔ∏è</span> Resultados y Visualizaciones
                            </h4>
                            <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 20px;">
                                <div style="background: #f8fafc; border-radius: 12px; overflow: hidden; border: 2px solid #e2e8f0;">
                                    <img src="images/image1.png" alt="Cubos s√≠smicos sint√©ticos - Entrenamiento" style="width: 100%; height: auto; display: block;">
                                    <div style="padding: 15px; font-size: 0.9em; color: #64748b; text-align: center; font-weight: 500;">
                                        Cubos s√≠smicos sint√©ticos utilizados para entrenamiento
                                    </div>
                                </div>
                                <div style="background: #f8fafc; border-radius: 12px; overflow: hidden; border: 2px solid #e2e8f0;">
                                    <img src="images/image2.png" alt="Cubos s√≠smicos sint√©ticos - Testeo" style="width: 100%; height: auto; display: block;">
                                    <div style="padding: 15px; font-size: 0.9em; color: #64748b; text-align: center; font-weight: 500;">
                                        Cubos s√≠smicos de testeo
                                    </div>
                                </div>
                                <div style="background: #f8fafc; border-radius: 12px; overflow: hidden; border: 2px solid #e2e8f0;">
                                    <img src="images/image3.png" alt="Arquitectura del modelo" style="width: 100%; height: auto; display: block;">
                                    <div style="padding: 15px; font-size: 0.9em; color: #64748b; text-align: center; font-weight: 500;">
                                        Arquitectura del modelo CNN 3D
                                    </div>
                                </div>
                                <div style="background: #f8fafc; border-radius: 12px; overflow: hidden; border: 2px solid #e2e8f0;">
                                    <img src="images/image4.png" alt="Resultados en datos reales" style="width: 100%; height: auto; display: block;">
                                    <div style="padding: 15px; font-size: 0.9em; color: #64748b; text-align: center; font-weight: 500;">
                                        Resultados en datos reales
                                    </div>
                                </div>
                                <div style="background: #f8fafc; border-radius: 12px; overflow: hidden; border: 2px solid #e2e8f0;">
                                    <img src="images/image5.png" alt="Caso real offshore" style="width: 100%; height: auto; display: block;">
                                    <div style="padding: 15px; font-size: 0.9em; color: #64748b; text-align: center; font-weight: 500;">
                                        Aplicaci√≥n en caso real offshore
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>

                                        <!-- Caso de Uso 2 -->
                    <div class="use-case-card">
                        <div class="use-case-header">
                            <div class="use-case-number">2</div>
                            <h3 class="use-case-title">Clasificaci√≥n No Supervisada de Facies S√≠smicas con LMVAE</h3>
                        </div>
                        
                        <div class="use-case-section">
                            <h4 class="use-case-section-title">üìã Contexto</h4>
                            <div class="use-case-content">
                                <p>La caracterizaci√≥n de facies s√≠smicas es un proceso esencial para comprender la arquitectura interna de los reservorios. A diferencia de la detecci√≥n de fallas, la clasificaci√≥n de facies depende de patrones m√°s sutiles del volumen s√≠smico: litolog√≠as, texturas, geometr√≠as deposicionales y variaciones de estratigraf√≠a fina.</p>
                                <p>Hist√≥ricamente, este trabajo se realizaba mediante m√©todos supervisados que requieren etiquetas geol√≥gicas o clasificaci√≥n manual previa, lo cual es costoso, lento y dif√≠cil de escalar. La exploraci√≥n moderna requiere enfoques no supervisados que permitan identificar grupos y patrones directamente desde los vol√∫menes s√≠smicos, sin necesidad de datos etiquetados.</p>
                            </div>
                        </div>
                        
                        <div class="use-case-section">
                            <h4 class="use-case-section-title">‚ö†Ô∏è Problem√°tica</h4>
                            <div class="use-case-content">
                                <p>La clasificaci√≥n de facies presenta varios desaf√≠os:</p>
                                <ul>
                                    <li><strong>No existen etiquetas "verdaderas"</strong> para entrenar modelos supervisados en la mayor√≠a de los proyectos</li>
                                    <li>Los <strong>patrones de facies son m√°s complejos y sutiles</strong> que las fallas, lo que dificulta el uso de CNNs simples</li>
                                    <li>La separaci√≥n espacial de facies requiere <strong>capturar relaciones de alta dimensi√≥n</strong>, no detectables con atributos tradicionales</li>
                                    <li>Los modelos de clustering cl√°sicos (PCA, k-means, GMM) <strong>no logran capturar la estructura real</strong> de los vol√∫menes</li>
                                    <li>Los m√©todos avanzados (VAEs, modelos de mezcla) <strong>demandan mucho poder de c√≥mputo</strong>, especialmente con vol√∫menes 3D completos</li>
                                </ul>
                                <p>Esto genera la necesidad de un m√©todo no supervisado que pueda aprender representaciones √∫tiles, separables y f√≠sicamente coherentes.</p>
                            </div>
                        </div>
                        
                        <div class="use-case-section">
                            <h4 class="use-case-section-title">‚úÖ Soluci√≥n Propuesta</h4>
                            <div class="use-case-content">
                                <p><strong>La soluci√≥n combina:</strong></p>
                                <ul>
                                    <li>El enfoque del <span class="paper-reference">üìÑ Paper: Lognormal Mixture-based Variational Autoencoder (LMVAE)</span> para clustering no supervisado</li>
                                    <li>Un pipeline propio basado en vol√∫menes s√≠smicos sint√©ticos, los mismos del Caso de Uso 1</li>
                                    <li>Un dise√±o centrado en atributos linealmente independientes, clave para separar las facies en el espacio latente</li>
                                </ul>
                                
                                <p><strong>Fundamento t√©cnico:</strong></p>
                                <p>El LMVAE utiliza un autoencoder variacional con una mezcla lognormal que:</p>
                                <ul>
                                    <li>Aprende una representaci√≥n latente compacta del volumen s√≠smico</li>
                                    <li>Captura distribuciones complejas sin asumir gaussianidad</li>
                                    <li>Facilita la clusterizaci√≥n directa del espacio latente, sin necesidad de etiquetas</li>
                                </ul>
                                
                                <p><strong>Uso de cubos sint√©ticos:</strong></p>
                                <p>Tal como en el Caso 1, se emplearon cubos s√≠smicos sint√©ticos porque:</p>
                                <ul>
                                    <li>Permiten controlar variaciones litol√≥gicas y estratigr√°ficas</li>
                                    <li>Son ideales para experimentaci√≥n con diferentes geometr√≠as deposicionales</li>
                                    <li>Generalizan muy bien a datos reales onshore y offshore</li>
                                    <li>Evitan costos y restricciones de confidencialidad</li>
                                </ul>
                                
                                <p><strong>1. Atributos linealmente independientes:</strong></p>
                                <p>Para mejorar la calidad del embedding latente y la separaci√≥n de clusters, se prioriz√≥ un conjunto de atributos:</p>
                                <ul>
                                    <li>Estad√≠sticos</li>
                                    <li>Geom√©tricos</li>
                                    <li>Texturales</li>
                                    <li>Derivados locales del cubo</li>
                                </ul>
                                <p>La condici√≥n de <strong>independencia lineal</strong> permite:</p>
                                <ul>
                                    <li>‚úÖ Reducir redundancia</li>
                                    <li>‚úÖ Evitar colinealidad</li>
                                    <li>‚úÖ Maximizar la informaci√≥n √∫til para el modelo</li>
                                    <li>‚úÖ Mejorar la separabilidad de clusters en el espacio latente</li>
                                </ul>
                                <p>Esto fue fundamental para lograr que el LMVAE identifique facies geol√≥gicamente coherentes.</p>
                                
                                <p><strong>2. Manejo del poder de c√≥mputo requerido:</strong></p>
                                <p>A diferencia del Caso 1, este enfoque exige una infraestructura m√°s robusta:</p>
                                <ul>
                                    <li>GPUs con memoria extendida</li>
                                    <li>Procesamiento por bloques 3D</li>
                                    <li>T√©cnicas de optimizaci√≥n de entrenamiento</li>
                                    <li>Batch sizes adaptativos</li>
                                </ul>
                                <p>Se dise√±√≥ un pipeline que permite entrenar el LMVAE de manera eficiente, incluso combinando procesamiento distribuido cuando es necesario.</p>
                                
                                <p><strong>Valor para el negocio:</strong></p>
                                <ul>
                                    <li>‚úÖ Identificaci√≥n autom√°tica de facies, sin necesidad de etiquetas</li>
                                    <li>‚úÖ Mejor entendimiento de heterogeneidades internas del reservorio</li>
                                    <li>‚úÖ Reducci√≥n de tiempos, al evitar clasificaciones manuales o semisupervisadas</li>
                                    <li>‚úÖ Mayor coherencia geol√≥gica gracias a atributos independientes y embebidos de alta calidad</li>
                                    <li>‚úÖ Capacidad de escalar a m√∫ltiples cuencas y entornos (onshore y offshore)</li>
                                    <li>‚úÖ C√≥digo libre, eliminando dependencias de software propietario</li>
                                </ul>
                            </div>
                        </div>
                        
                        <!-- Gallery Section Case 2 -->
                        <div style="margin-top: 30px; padding-top: 30px; border-top: 2px solid #e2e8f0;">
                            <h4 style="font-size: 1.3em; font-weight: 600; color: #1e293b; margin-bottom: 20px; display: flex; align-items: center; gap: 10px;">
                                <span>üñºÔ∏è</span> Resultados y Visualizaciones
                            </h4>
                            <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(400px, 1fr)); gap: 20px;">
                                <div style="background: #f8fafc; border-radius: 12px; overflow: hidden; border: 2px solid #e2e8f0;">
                                    <img src="images/case2/image1.png" alt="Pipeline LMVAE para clasificaci√≥n de facies" style="width: 100%; height: auto; display: block;">
                                    <div style="padding: 15px; font-size: 0.9em; color: #64748b; text-align: center; font-weight: 500;">
                                        Pipeline completo del LMVAE para clasificaci√≥n no supervisada de facies
                                    </div>
                                </div>
                                <div style="background: #f8fafc; border-radius: 12px; overflow: hidden; border: 2px solid #e2e8f0;">
                                    <img src="images/case2/image2.png" alt="Resultados de clustering en espacio latente" style="width: 100%; height: auto; display: block;">
                                    <div style="padding: 15px; font-size: 0.9em; color: #64748b; text-align: center; font-weight: 500;">
                                        Resultados del clustering en el espacio latente y visualizaci√≥n de facies identificadas
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
            </div>
        </div>

        <div class="footer">
            <p><strong>Informe de Investigaci√≥n T√©cnica</strong></p>
            <p>Generado por sistema automatizado de an√°lisis bibliogr√°fico</p>
            <p style="margin-top: 20px; opacity: 0.7; font-size: 0.9em;">
                Los papers han sido seleccionados por relevancia al tema de IA aplicada a interpretaci√≥n
                s√≠smica.<br>
                Las recomendaciones se basan en madurez tecnol√≥gica y potencial impacto demostrado en la literatura.
            </p>
        </div>
    </div>

    <script>
        function switchTab(tabName) {
            // Remove active class from all buttons and tabs
            const buttons = document.querySelectorAll('.tab-button');
            const tabs = document.querySelectorAll('.tab-content');

            buttons.forEach(btn => btn.classList.remove('active'));
            tabs.forEach(tab => tab.classList.remove('active'));

            // Add active class to selected button and tab
            const activeButton = event.target;
            const activeTab = document.getElementById(tabName + '-tab');

            activeButton.classList.add('active');
            activeTab.classList.add('active');
        }
    </script>
</body>

</html>